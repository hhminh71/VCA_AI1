import streamlit as st
import google.generativeai as genai
import os

# --- C√ÅC H√ÄM TI·ªÜN √çCH ---

def rfile(name_file):
    """H√†m ƒë·ªçc n·ªôi dung t·ª´ file vƒÉn b·∫£n."""
    try:
        with open(name_file, "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file '{name_file}'. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.")
        return "" # Tr·∫£ v·ªÅ chu·ªói r·ªóng n·∫øu file kh√¥ng t·ªìn t·∫°i

# --- C·∫§U H√åNH V√Ä GIAO DI·ªÜN ---

# C·∫•u h√¨nh trang
st.set_page_config(page_title="Tr·ª£ l√Ω AI", page_icon="ü§ñ")

# Hi·ªÉn th·ªã logo (n·∫øu c√≥)
if os.path.exists("logo.png"):
    col1, col2, col3 = st.columns([3, 2, 3])
    with col2:
        st.image("logo.png", use_container_width=True)

# Hi·ªÉn th·ªã ti√™u ƒë·ªÅ
title_content = rfile("00.xinchao.txt")
st.markdown(
    f"""<h1 style="text-align: center; font-size: 24px;">{title_content}</h1>""",
    unsafe_allow_html=True
)

# --- C·∫§U H√åNH API GEMINI ---

# L·∫•y Gemini API key t·ª´ st.secrets v√† c·∫•u h√¨nh
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=gemini_api_key)
except (KeyError, AttributeError):
    st.error("L·ªói: Vui l√≤ng thi·∫øt l·∫≠p 'GEMINI_API_KEY' trong m·ª•c Secrets c·ªßa Streamlit.")
    st.stop()


# --- KH·ªûI T·∫†O L·ªäCH S·ª¨ CHAT ---

# ƒê·ªçc n·ªôi dung hu·∫•n luy·ªán t·ª´ c√°c file
system_prompt = rfile("01.system_trainning.txt")
initial_assistant_message_content = rfile("02.assistant.txt")

# C·∫•u h√¨nh an to√†n ƒë·ªÉ gi·∫£m kh·∫£ nƒÉng b·ªã ch·∫∑n
safety_settings = [
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_ONLY_HIGH",
    },
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_ONLY_HIGH",
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_ONLY_HIGH",
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_ONLY_HIGH",
    },
]

# Kh·ªüi t·∫°o model Gemini v·ªõi system prompt v√† c·∫•u h√¨nh an to√†n
model_name = 'gemini-1.5-pro' # S·ª≠ d·ª•ng model 1.5 Pro ·ªïn ƒë·ªãnh

try:
    model = genai.GenerativeModel(
        model_name=model_name,
        system_instruction=system_prompt,
        safety_settings=safety_settings
    )
except Exception as e:
    st.error(f"L·ªói kh·ªüi t·∫°o model Gemini: {e}")
    st.stop()


# Kh·ªüi t·∫°o session state ƒë·ªÉ l∆∞u l·ªãch s·ª≠ chat
if "messages" not in st.session_state:
    # B·∫Øt ƒë·∫ßu l·ªãch s·ª≠ v·ªõi tin nh·∫Øn ch√†o m·ª´ng c·ªßa tr·ª£ l√Ω
    st.session_state.messages = [{"role": "assistant", "content": initial_assistant_message_content}]

# --- GIAO DI·ªÜN CHAT ---

# CSS ƒë·ªÉ t√πy ch·ªânh giao di·ªán tin nh·∫Øn
st.markdown(
    """
    <style>
        .assistant {
            padding: 10px;
            border-radius: 10px;
            max-width: 75%;
            background: none;
            text-align: left;
            display: flex;
            align-items: flex-start;
            gap: 10px;
        }
        .user {
            padding: 10px;
            border-radius: 10px;
            max-width: 75%;
            background: none;
            text-align: right;
            margin-left: auto;
        }
        .assistant-icon {
            font-size: 20px;
            line-height: 1.5;
        }
        .message-content {
            flex: 1;
        }
    </style>
    """,
    unsafe_allow_html=True
)

# Hi·ªÉn th·ªã l·ªãch s·ª≠ tin nh·∫Øn ƒë√£ l∆∞u
for message in st.session_state.messages:
    if message["role"] == "assistant":
        st.markdown(f'<div class="assistant"><span class="assistant-icon">ü§ñ</span> <span class="message-content">{message["content"]}</span></div>', unsafe_allow_html=True)
    elif message["role"] == "user":
        st.markdown(f'<div class="user">{message["content"]}</div>', unsafe_allow_html=True)

# --- X·ª¨ L√ù INPUT C·ª¶A NG∆Ø·ªúI D√ôNG ---

if prompt := st.chat_input("S·∫øp nh·∫≠p n·ªôi dung c·∫ßn trao ƒë·ªïi ·ªü ƒë√¢y nh√©?"):
    # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ v√† hi·ªÉn th·ªã
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.markdown(f'<div class="user">{prompt}</div>', unsafe_allow_html=True)

    # Chuy·ªÉn ƒë·ªïi l·ªãch s·ª≠ sang ƒë·ªãnh d·∫°ng Gemini y√™u c·∫ßu (user/model)
    gemini_history = []
    for msg in st.session_state.messages:
        role = "model" if msg["role"] == "assistant" else "user"
        gemini_history.append({"role": role, "parts": [msg["content"]]})

    # B·∫Øt ƒë·∫ßu chat session v√† g·ª≠i tin nh·∫Øn
    try:
        chat = model.start_chat(history=gemini_history[:-1])
        response_stream = chat.send_message(gemini_history[-1]['parts'][0], stream=True)

        # Hi·ªÉn th·ªã ph·∫£n h·ªìi c·ªßa tr·ª£ l√Ω (d·∫°ng streaming)
        with st.chat_message("assistant", avatar="ü§ñ"):
            message_placeholder = st.empty()
            full_response = ""
            try:
                for chunk in response_stream:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "‚ñå")
                message_placeholder.markdown(full_response)
            except ValueError:
                # B·∫Øt l·ªói n·∫øu ph·∫£n h·ªìi b·ªã ch·∫∑n
                message_placeholder.markdown("‚ö†Ô∏è Xin l·ªói, ph·∫£n h·ªìi ƒë√£ b·ªã ch·∫∑n do ch√≠nh s√°ch an to√†n. Vui l√≤ng th·ª≠ l·∫°i v·ªõi m·ªôt c√¢u h·ªèi kh√°c.")
                full_response = "‚ö†Ô∏è Ph·∫£n h·ªìi b·ªã ch·∫∑n." # L∆∞u tin nh·∫Øn l·ªói v√†o l·ªãch s·ª≠

        # Ch·ªâ l∆∞u v√†o l·ªãch s·ª≠ n·∫øu ph·∫£n h·ªìi kh√¥ng r·ªóng
        if full_response:
             st.session_state.messages.append({"role": "assistant", "content": full_response})

    except Exception as e:
        st.error(f"ƒê√£ c√≥ l·ªói x·∫£y ra khi g·ªçi API c·ªßa Gemini: {e}")
